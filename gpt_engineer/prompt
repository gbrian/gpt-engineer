Create a summary from all files with the name of the file and a summary of the file contents
Summarized as much as possible to save space keeo only what can be relevant when deciding
which files can be affected by a future task like: "Create a new functionality about X or Y" or "Change the implementation of X by adding Y".

[[PROMPT]]
Add prompt parameter of type string to gtp_engineer and fix api and cli accordingly

[[PROMPT]]
If prompt parameter is set save it in a file named prompt at workspace_path

[[PROMPT]]
Create new function at core/__init__.py index_content it will receive a path and extensions parameters and will traverse all file
and for each file with a valid extension will call to new class Summary summary_file method.

Create Summary class at core/summary.py and add methods:
- summary_file: Will receive a file_name and data byte[] and will send to the AI to be summarized using SUMMARY_PROMPT prompt below.
                Results will be added to the main summary.txt file replacing current text defined by ## FILE: file_name and < FILE: file_name
                Create the prompt replacing the [[XXX]] values

SUMMARY_PROMPT
Summarize this file of type [[EXTENSION]]
Keep all sensitive information extrict like class names, function names and other relevan information.
Reduce to the maximum.
File content:
[[FILE_CONTENT]]

[[AI]]
PLANNING:
1. In the `core/__init__.py` file, we need to create a new function `index_content`. This function will take two parameters: `path` and `extensions`. It will traverse all files in the given path and for each file with a valid extension, it will call the `summary_file` method of the `Summary` class.

2. We need to create a new file `core/summary.py` and add a new class `Summary` in it. This class will have a method `summary_file` which will take two parameters: `file_name` and `data`. This method will send the data to the AI to be summarized using the `SUMMARY_PROMPT` prompt. The results will be added to the main `summary.txt` file replacing the current text defined by `## FILE: file_name` and `< FILE: file_name`. The prompt will be created by replacing the `[[XXX]]` values in the `SUMMARY_PROMPT`.

OUTPUT:
```python
core/__init__.py
<<<<<<< HEAD
    from gpt_engineer.core.db import DB, DBs, DBPrompt, archive
    from gpt_engineer.core.steps import STEPS, Config as StepsConfig
    from gpt_engineer.cli.collect import collect_learnings
    from gpt_engineer.cli.learning import check_collection_consent
=======
    from gpt_engineer.core.db import DB, DBs, DBPrompt, archive
    from gpt_engineer.core.steps import STEPS, Config as StepsConfig
    from gpt_engineer.core.summary import Summary
    from gpt_engineer.cli.collect import collect_learnings
    from gpt_engineer.cli.learning import check_collection_consent

    # Add new function index_content
    def index_content(path: str, extensions: list):
        summary = Summary()
        for root, dirs, files in os.walk(path):
            for file in files:
                if file.endswith(tuple(extensions)):
                    with open(os.path.join(root, file), 'rb') as f:
                        data = f.read()
                    summary.summary_file(file, data)
>>>>>>> updated
```

```python
core/summary.py
<<<<<<< HEAD
=======
class Summary:
    def summary_file(self, file_name: str, data: bytes):
        SUMMARY_PROMPT = "Summarize this file of type [[EXTENSION]]\nKeep all sensitive information extrict like class names, function names and other relevan information.\nReduce to the maximum.\nFile content:\n[[FILE_CONTENT]]"
        extension = os.path.splitext(file_name)[1]
        file_content = data.decode('utf-8')
        prompt = SUMMARY_PROMPT.replace('[[EXTENSION]]', extension).replace('[[FILE_CONTENT]]', file_content)
        # Send the prompt to the AI and get the summarized content
        summarized_content = AI.summarize(prompt)
        # Add the summarized content to the main summary.txt file
        with open('summary.txt', 'r+') as f:
            content = f.read()
            start_index = content.find(f'## FILE: {file_name}')
            end_index = content.find(f'< FILE: {file_name}')
            if start_index != -1 and end_index != -1:
                f.seek(start_index)
                f.write(f'## FILE: {file_name}\n{summarized_content}\n< FILE: {file_name}')
            else:
                f.write(f'\n## FILE: {file_name}\n{summarized_content}\n< FILE: {file_name}')
>>>>>>> updated
```
Note: The `AI.summarize(prompt)` method is a placeholder and needs to be replaced with the actual method that sends the prompt to the AI and gets the summarized content.

[[PROMPT]]
index_content must pass ai parameter to summary_file.
summary_file will call ai.next with the generated prompt.
Fix functions with missing parameters.
Documen classes

[[AI]]
PLANNING:
We need to change the `index_content` function to pass the `ai` parameter to the `summary_file` function. This is because `summary_file` will call `ai.next` with the generated prompt. Also, we need to fix the `index_content` function to include the missing parameters `model`, `temperature`, `azure_endpoint`, and `ai_cache`. Finally, we need to add documentation for the `index_content` function.

OUTPUT:
```python
core/__init__.py
<<<<<<< HEAD
# Add new function index_content
def index_content(path: str, extensions: list):
    ai = AI(
        model_name=model,
        temperature=temperature,
        azure_endpoint=azure_endpoint,
        cache=DB(memory_path / "cache") if ai_cache else None,
    )
    summary = Summary()
    for root, dirs, files in os.walk(path):
        for file in files:
            if file.endswith(tuple(extensions)):
                with open(os.path.join(root, file), "rb") as f:
                    data = f.read()
                summary.summary_file(file, data)
=======
# Add new function index_content
def index_content(path: str, extensions: list, model: str, temperature: float, azure_endpoint: str, ai_cache: bool):
    """
    Index the content of files in a given path and generate a summary.

    This function walks through the directory specified by the path, and for each file
    with an extension included in the extensions list, it reads the file and generates
    a summary using the AI model.

    Parameters
    ----------
    path : str
        The path of the directory to index.
    extensions : list
        The list of file extensions to include in the indexing.
    model : str
        The name of the AI model to use.
    temperature : float
        The temperature setting for the AI model.
    azure_endpoint : str
        The Azure endpoint URL, if applicable.
    ai_cache : bool
        Whether to use AI cache.

    """
    ai = AI(
        model_name=model,
        temperature=temperature,
        azure_endpoint=azure_endpoint,
        cache=DB(memory_path / "cache") if ai_cache else None,
    )
    summary = Summary()
    for root, dirs, files in os.walk(path):
        for file in files:
            if file.endswith(tuple(extensions)):
                with open(os.path.join(root, file), "rb") as f:
                    data = f.read()
                summary.summary_file(file, data, ai)
>>>>>>> updated
```

[[PROMPT]]
Documment class Summary and add ai:AI parameter to the constructor.
Fix code using Summary.

[[AI]]
PLANNING:
We need to add a constructor to the Summary class that accepts an AI instance as a parameter. This is because the Summary class needs to use the AI instance to generate summaries. We also need to document the Summary class to explain its purpose and usage.

In the `index_content` function, we need to pass the `ai` instance when creating a new `Summary` instance.

OUTPUT:
```python
core/__init__.py
<<<<<<< HEAD
class Summary:
=======
class Summary:
    """
    A class to generate summaries of file contents using an AI model.

    This class provides methods to read the contents of a file and generate a summary
    using a specified AI model. It is designed to work with text files.

    Attributes
    ----------
    ai : AI
        The AI instance used to generate summaries.

    Methods
    -------
    summary_file(file_name, data) -> str:
        Generate a summary of the contents of a file.
    """
    def __init__(self, ai: AI):
        """
        Initialize the Summary class.

        Parameters
        ----------
        ai : AI
            The AI instance to use for generating summaries.
        """
        self.ai = ai
>>>>>>> updated
```

```python
core/__init__.py
<<<<<<< HEAD
    summary = Summary()
=======
    summary = Summary(ai)
>>>>>>> updated
```


[[PROMPT]]
Ensure ask_for_selection method allows user to enter a list of values separated by comma.
This values can be:
 * A single number
 * A star-end range where start and end indexes are included as well
 * A text that will be use to match the paths, all paths matching will be included

 Ensure the method is doing well or fix the possible errors
 \s[[AI]]
PLANNING:
The `ask_for_selection` method in the `TerminalFileSelector` class is already designed to accept a list of values separated by commas. However, it seems there might be some issues with the current implementation.

The current implementation splits the user input by commas and then processes each entry. If the entry contains a dash, it is treated as a range and all numbers within that range are added to the selected paths. If the entry does not contain a dash, it is treated as a single number and that number is added to the selected paths.

However, the current implementation does not handle the case where the user input is a text that should be used to match the paths. To fix this, we need to add a condition to check if the entry is a number or a text. If it is a text, we should filter the paths based on whether the text is in the path.

We also need to handle the case where the user input is not a valid number or range. Currently, the program exits with an error message if this happens. Instead, we should prompt the user to enter a valid input.

OUTPUT:
```python
cli/file_selector.py
<<<<<<< HEAD
    def ask_for_selection(self) -> List[str]:
        """
        Prompts the user to select files by providing a series of index numbers, ranges, or 'all' to select everything.

        Returns:
            List[str]: A list of selected file paths based on user's input.

        Notes:
            - Users can select files by entering index numbers separated by commas or spaces.
            - Ranges can be specified using a dash.
            - Example input: 1,2,3-5,7,9,13-15,18,20
            - Users can also input 'all' to select all displayed files.
        """
        user_input = input(
            "\n".join(
                [
                    "Select files by entering the numbers separated by commas/spaces or",
                    "specify range with a dash. ",
                    "Example: 1,2,3-5,7,9,13-15,18,20 (enter 'all' to select everything)",
                    "\n\nSelect files:",
                ]
            )
        )
        selected_paths = []
        if user_input.lower() == "all":
            selected_paths = self.file_path_list
        else:
            try:
                user_input = (
                    user_input.replace(" ", ",") if " " in user_input else user_input
                )
                selected_files = [
                    selection_entry.strip().split("-")
                    for selection_entry in user_input.split(",")
                ]

                for start, end in selected_files:
                    if end:
                        for num in range(int(start), int(end) + 1):
                            selected_paths.append(str(self.selectable_file_paths[num]))
                    else:
                        selected_paths.append(str(self.selectable_file_paths[int(start)]))
            except ValueError as ex:
                print(
                    f"Please use a valid number/series of numbers. Error in: {user_input}\n"
                )
                logging.error(ex)
                sys.exit(1)

        return selected_paths
=======
    def ask_for_selection(self) -> List[str]:
        """
        Prompts the user to select files by providing a series of index numbers, ranges, or 'all' to select everything.

        Returns:
            List[str]: A list of selected file paths based on user's input.

        Notes:
            - Users can select files by entering index numbers separated by commas or spaces.
            - Ranges can be specified using a dash.
            - Example input: 1,2,3-5,7,9,13-15,18,20 or file nname like 'settings.py' (enter 'all' to select everything)",
            "\n\nSelect files:",
        """
        user_input = input(
            "\n".join(
                [
                    "Select files by entering the numbers separated by commas/spaces or",
                    "specify range with a dash. ",
                    "Example: 1,2,3-5,7,9,13-15,18,20 or file nname like 'settings.py' (enter 'all' to select everything)",
                    "\n\nSelect files:",
                ]
            )
        )
        selected_paths = []
        all_paths = self.selectable_file_paths.values()

        def process_selection(entry):
            parts = entry.strip().split("-")
            start = parts[0]
            end = parts[-1]
            start = int(start) if IS_NUM.match(start) else None
            end = int(end) if end != start and IS_NUM.match(end) else None
            return start, end, entry

        if user_input.lower() == "all":
            selected_paths = self.file_path_list
        else:
            try:
                user_input = (
                    user_input.replace(" ", ",") if " " in user_input else user_input
                )
                logging.info(f"[ask_for_selection] user_inputs are {type(user_input.split(',')[0])}")
                selected_files = [process_selection(selection_entry) for selection_entry in user_input.split(",")]

                for start, end, entry in selected_files:
                    logging.info(f"[ask_for_selection] processing selection {(start, end, entry)}")
                    if end:
                        for num in range(start, end + 1):
                            selected_paths.append(str(self.selectable_file_paths[num]))
                    elif start:
                        selected_paths.append(str(self.selectable_file_paths[start]))
                    else:
                        paths = list(filter(lambda path: entry in str(path) , all_paths))
                        selected_paths = selected_paths + paths

            except ValueError as ex:
                print(
                    f"Please use a valid number/series of numbers or file name. Error in: {user_input}\n"
                )
                logging.error(ex)
                sys.exit(1)

        return selected_paths
>>>>>>> updated
```

[[PROMPT]]

Create tests for parse_all_edits.
## Cases:

### Text with DIFF instructions to change files

"This is an example response with a diff syntax inside

OUTPUT:
```python
cli/file_selector.py
<<<<<<< HEAD
    ## Section to change
=======
    ## Secrion with a change
>>>>>>> updated
```

"

### Text with multiple DIFF instructions to change files

"This is an example response with a diff syntax inside

OUTPUT:
```python
cli/file_selector.py
<<<<<<< HEAD
    ## Section to change
=======
    ## Secrion with a change
>>>>>>> updated
```

More comments

```python
<<<<<<< HEAD
    ## Section to change
=======
    ## Secrion with a change
>>>>>>> updated
```

"

### DIFF instructions can contain code sections

"This is an example response with a diff syntax inside

OUTPUT:
```python
cli/file_selector.py
<<<<<<< HEAD
    ```python
    cli/file_selector.py
        def this_is_python_code:
            pass
    ```
=======
    ```python
    cli/file_selector.py
        def this_is_python_code:
            """ A python function """
            pass
    ```
>>>>>>> updated
```

More comments

```python
<<<<<<< HEAD
    ## Section to change
=======
    ## Secrion with a change
>>>>>>> updated
```

"





[[AI]]
PLANNING:
We need to create a new test file for the `parse_all_edits` function in the `chat_to_files.py` module. The test file will be named `test_chat_to_files.py` and will be located in the `tests` directory.

In this file, we will define a new function for each test case. Each function will call `parse_all_edits` with the provided input and then assert that the output matches the expected result.

The first test case will be `test_parse_all_edits_single_diff`, which will test the function with a single diff instruction.

The second test case will be `test_parse_all_edits_multiple_diffs`, which will test the function with multiple diff instructions.

The third test case will be `test_parse_all_edits_diffs_with_code`, which will test the function with diff instructions that contain code sections.

For each test case, we will need to define the expected output. This will be a list of `Edit` objects, each of which will contain the filename, before and after text, and full text of a diff instruction.

OUTPUT:
```python
tests/test_chat_to_files.py
<<<<<<< HEAD

=======
import pytest
from gpt_engineer.core.chat_to_files import parse_all_edits, Edit

def test_parse_all_edits_single_diff():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output

def test_parse_all_edits_multiple_diffs():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```\n\nMore comments\n\n```python\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        ),
        Edit(
            filename="",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output

def test_parse_all_edits_diffs_with_code():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```\n=======\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```\n>>>>>>> updated\n```\n\nMore comments\n\n```python\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```",
            after="```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```\n=======\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```\n>>>>>>> updated"
        ),
        Edit(
            filename="",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output
>>>>>>> updated
```
ERROR: Could not parse following text as code edit:
<<<<<<< HEAD

=======
import pytest
from gpt_engineer.core.chat_to_files import parse_all_edits, Edit

def test_parse_all_edits_single_diff():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output

def test_parse_all_edits_multiple_diffs():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```\n\nMore comments\n\n```python\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        ),
        Edit(
            filename="",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output

def test_parse_all_edits_diffs_with_code():
    input_text = "This is an example response with a diff syntax inside\n\nOUTPUT:\n```python\ncli/file_selector.py\n<<<<<<< HEAD\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```\n=======\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```\n>>>>>>> updated\n```\n\nMore comments\n\n```python\n<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated\n```"
    expected_output = [
        Edit(
            filename="cli/file_selector.py",
            before="```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```",
            after="```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```",
            full_text="cli/file_selector.py\n<<<<<<< HEAD\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            pass\n    ```\n=======\n    ```python\n    cli/file_selector.py\n        def this_is_python_code:\n            \"\"\" A python function \"\"\"\n            pass\n    ```\n>>>>>>> updated"
        ),
        Edit(
            filename="",
            before="## Section to change",
            after="## Secrion with a change",
            full_text="<<<<<<< HEAD\n    ## Section to change\n=======\n    ## Secrion with a change\n>>>>>>> updated"
        )
    ]
    assert parse_all_edits(input_text) == expected_output
>>>>>>> updated

[[PROMPT]]
Add new parameter -f --file-selector to cli to force the request of files affected. It will delete ".gpteng/file_list.txt"
[[AI]]
PLANNING:
We need to add a new parameter to the CLI command to allow users to force the request of files affected. This will be done by adding a new argument to the `main` function and passing it to the `gtp_engineer` function. We will also need to add a condition to delete the file ".gpteng/file_list.txt" if the new parameter is set to True.

OUTPUT:
```python
cli/main.py
<<<<<<< HEAD
@app.command()
def main(
    project_path: str = typer.Argument("projects/example", help="path"),
    model: str = typer.Argument(MODEL, help="model id string"),
    temperature: float = TEMPERATURE,
    steps_config: StepsConfig = typer.Option(
        StepsConfig.DEFAULT, "--steps", "-s", help="decide which steps to run"
    ),
    improve_mode: bool = typer.Option(
        False,
        "--improve",
        "-i",
        help="Improve code from existing project.",
    ),
    lite_mode: bool = typer.Option(
        False,
        "--lite",
        "-l",
        help="Lite mode - run only the main prompt.",
    ),
    azure_endpoint: str = typer.Option(
        "",
        "--azure",
        "-a",
        help="""Endpoint for your Azure OpenAI Service (https://xx.openai.azure.com).
            In that case, the given model is the deployment name chosen in the Azure AI Studio.""",
    ),
    use_custom_preprompts: bool = typer.Option(
        False,
        "--use-custom-preprompts",
        help="""Use your project's custom preprompts instead of the default ones.
          Copies all original preprompts to the project's workspace if they don't exist there.""",
    ),
    ai_cache: bool = typer.Option(
        False,
        "--cache",
        "-c",
        help="Caches AI responses.",
    ),
    use_git: bool = typer.Option(
        False,
        "--git",
        "-g",
        help="Project uses git. Commit changes to keep track and easy changes detection.",
    ),
    prompt_file: str = typer.Option(
        False,
        "--prompt",
        "-p",
        help="Use this prompt. This will replace workspce's prompt with file contents.",
    ),
    verbose: bool = typer.Option(False, "--verbose", "-v"),
    prompt: str = typer.Option("", "--prompt-text", "-pt", help="Custom prompt text."),
):
    gtp_engineer(
        project_path=project_path,
        model=model,
        temperature=temperature,
        steps_config=steps_config,
        improve_mode=improve_mode,
        lite_mode=lite_mode,
        azure_endpoint=azure_endpoint,
        use_custom_preprompts=use_custom_preprompts,
        ai_cache=ai_cache,
        use_git=use_git,
        prompt_file=prompt_file,
        verbose=verbose,
        prompt=prompt,
    )
=======
@app.command()
def main(
    project_path: str = typer.Argument("projects/example", help="path"),
    model: str = typer.Argument(MODEL, help="model id string"),
    temperature: float = TEMPERATURE,
    steps_config: StepsConfig = typer.Option(
        StepsConfig.DEFAULT, "--steps", "-s", help="decide which steps to run"
    ),
    improve_mode: bool = typer.Option(
        False,
        "--improve",
        "-i",
        help="Improve code from existing project.",
    ),
    lite_mode: bool = typer.Option(
        False,
        "--lite",
        "-l",
        help="Lite mode - run only the main prompt.",
    ),
    azure_endpoint: str = typer.Option(
        "",
        "--azure",
        "-a",
        help="""Endpoint for your Azure OpenAI Service (https://xx.openai.azure.com).
            In that case, the given model is the deployment name chosen in the Azure AI Studio.""",
    ),
    use_custom_preprompts: bool = typer.Option(
        False,
        "--use-custom-preprompts",
        help="""Use your project's custom preprompts instead of the default ones.
          Copies all original preprompts to the project's workspace if they don't exist there.""",
    ),
    ai_cache: bool = typer.Option(
        False,
        "--cache",
        "-c",
        help="Caches AI responses.",
    ),
    use_git: bool = typer.Option(
        False,
        "--git",
        "-g",
        help="Project uses git. Commit changes to keep track and easy changes detection.",
    ),
    prompt_file: str = typer.Option(
        False,
        "--prompt",
        "-p",
        help="Use this prompt. This will replace workspce's prompt with file contents.",
    ),
    verbose: bool = typer.Option(False, "--verbose", "-v"),
    prompt: str = typer.Option("", "--prompt-text", "-pt", help="Custom prompt text."),
    file_selector: bool = typer.Option(False, "--file-selector", "-f", help="Force the request of files affected."),
):
    if file_selector:
        file_list_path = Path(".gpteng/file_list.txt")
        if file_list_path.exists():
            file_list_path.unlink()

    gtp_engineer(
        project_path=project_path,
        model=model,
        temperature=temperature,
        steps_config=steps_config,
        improve_mode=improve_mode,
        lite_mode=lite_mode,
        azure_endpoint=azure_endpoint,
        use_custom_preprompts=use_custom_preprompts,
        ai_cache=ai_cache,
        use_git=use_git,
        prompt_file=prompt_file,
        verbose=verbose,
        prompt=prompt,
        file_selector=file_selector,
    )
>>>>>>> updated
```
